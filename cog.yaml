build:
  gpu: true
  python_version: "3.11"
  # python_requirements is NOT used. All installation is manual.
  system_packages:
    - "build-essential"
    - "cmake"
    - "ninja-build"
    - "git"
    - "python3-dev"
    - "ffmpeg"
  secrets:
    - HUGGING_FACE_HUB_TOKEN
  run:
    # STEP 1: Upgrade pip and install the build-time dependency for flash-attn.
    - "pip install --upgrade pip packaging"

    # STEP 2: Install PyTorch, torchvision, and torchaudio from the official
    # PyTorch index for CUDA 11.8. This is the critical change.
    - "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
    - "pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu11torch2.4cxx11abiTRUE-cp311-cp311-linux_x86_64.whl"

    # STEP 3: Install the remaining packages.
    # Note: torch, torchvision, and torchaudio have been removed from this list.
    - 'pip install opencv-python>=4.9.0.80 diffusers>=0.31.0 "transformers>=4.49.0,<=4.51.3" tokenizers>=0.20.3 accelerate>=1.1.1 tqdm "imageio[ffmpeg]" easydict ftfy dashscope "numpy>=1.23.5,<2" openai-whisper HyperPyYAML onnxruntime inflect wetext omegaconf conformer hydra-core lightning rich gdown matplotlib wget pyarrow pyworld librosa decord modelscope GitPython'

    # STEP 4: Download model weights.
    - "huggingface-cli download Wan-AI/Wan2.2-S-2-V-14-B --local-dir ./Wan-2.2-S-2-V-14-B"

predict: "predict.py:Predictor"
